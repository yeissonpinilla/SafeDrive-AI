import pandas as pd

#Read the dataset
df = pd.read_csv('./Traffic_Collision_Data.csv')

df['y'] = df['Classification_Of_Accident']

#Remove columns that won't be useful
df.drop(['ID', 'Geo_ID', 'X', 'Y', 'Accident_Year', 'Location', 'Traffic_Control', 'X_Coordinate', 'Y_Coordinate', 'ObjectId', 'Classification_Of_Accident'], axis = 1, inplace = True)

#Convert column to right variable type
df['Accident_Date'] = pd.to_datetime(df['Accident_Date'])

print(df.shape)
df.info()
df.loc[:, ['Accident_Date']]
df.loc[:, ['y']]
df['y'].value_counts().plot(kind='bar')
df['y'].value_counts(normalize=False)





import numpy as np
#Feature engineering for Accident_Time
#Before starting, we need to remove all Unkown values from the dataset
df = df.loc[df['Accident_Time'] != 'Unknown']

#First step: convert time hh:mm to only mm
times = pd.to_datetime(df['Accident_Time'], format = '%H:%M', errors = 'coerce')
hours = times.dt.hour
minutes = times.dt.minute
time_minutes = (hours*60) + minutes

df['time_minutes'] = time_minutes

#Second step: create columns for sin_time and cosine_time
calculated_time = (2 * np.pi * df['time_minutes']) / 1440
df['sin_time'] = np.sin(calculated_time)
df['cos_time'] = np.cos(calculated_time)

#Third step: remove original Accident_Time column since it won't be of any use
df.drop(['Accident_Time'], axis = 1, inplace = True)

df.loc[:, ['sin_time', 'cos_time']]


#Feature engineer for Accident_Date, pretty similar to the approach used for Accident_Time, but converting dates into number of days. 
#First step: convert date into number of the day of the year.
df['Accident_Day'] = df['Accident_Date'].dt.dayofyear

#Second step: create columns for Sin_Accident_Day and Cos_Accident_Day
calculated_day = (2 * np.pi * df['Accident_Day']) / 366
df['Sin_Accident_Day'] = np.sin(calculated_day)
df['Cos_Accident_Day'] = np.cos(calculated_day)

#Third step: remove original Accident_Date column since it won't be of any use
df.drop(['Accident_Date'], axis = 1, inplace = True)

df.loc[:, ['Sin_Accident_Day', 'Cos_Accident_Day']]


#Feature engineeer for location type, consists on encoding, midblock is now 0 and intersection is now 1
df['Location_Type'] = df['Location_Type'].map({'Midblock': 0, 'Intersection': 1})
df['Location_Type'].unique()
df.loc[:, 'Location_Type']


from sklearn.preprocessing import LabelEncoder

#Feature engineer for Initial Impact Type, this time I'll use scikit learn to encode.
#First step: remove any nan values from dataset
df.dropna(subset = ['Initial_Impact_Type'], inplace = True)

#Second step: prepare encoder and encode
encoder = LabelEncoder()
df['Initial_Impact_Type'] = encoder.fit_transform(df['Initial_Impact_Type'])

df.loc[:, 'Initial_Impact_Type']



#Feature engineer for Road surface condition, this time I'll use scikit learn to encode.
#First step: remove any nan values from dataset
df.dropna(subset = ['Road_Surface_Condition'], inplace = True)

#Second step: prepare encoder and encode
encoder = LabelEncoder()
df['Road_Surface_Condition'] = encoder.fit_transform(df['Road_Surface_Condition'])
df.loc[:, 'Initial_Impact_Type']


#Feature engineer for Environment Condition, this time I'll use scikit learn to encode.
#First step: remove any nan values from dataset
df.dropna(subset = ['Environment_Condition'], inplace = True)

#Second step: prepare encoder and encode
encoder = LabelEncoder()
df['Environment_Condition'] = encoder.fit_transform(df['Environment_Condition'])

df.loc[:, 'Environment_Condition']


df = df[df['Light'] != '00 - Unknown']
df.loc[df['Light'] == '00 - Unknown', 'Light'].count()

encoder = LabelEncoder()
df['Light'] = encoder.fit_transform(df['Light'])

print(df['Light'].unique())
print(df.loc[:, 'Light'])

df = df[df['Max_Injury'] != 'NaN']
print(df.loc[df['Max_Injury'] == 'NaN', 'Light'].count())

encoder = LabelEncoder()
df['Max_Injury'] = encoder.fit_transform(df['Max_Injury'])
df['y'] = encoder.fit_transform(df['y'])

print(df['Max_Injury'].unique())
print(df.loc[:, 'Max_Injury'])

df[["Num_of_Bicycles", "Num_of_Motorcycles", "Num_of_Injuries", "Num_of_Minor_Injuries", "Num_of_Minimal_Injuries", "Num_of_Major_Injuries", "Num_of_Fatal_Injuries"]] = df[["Num_of_Bicycles", "Num_of_Motorcycles", "Num_of_Injuries", "Num_of_Minor_Injuries", "Num_of_Minimal_Injuries", "Num_of_Major_Injuries", "Num_of_Fatal_Injuries"]].fillna(0)


from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay
from sklearn.model_selection import RandomizedSearchCV, train_test_split
from scipy.stats import randint
from sklearn.tree import export_graphviz
from IPython.display import Image
#import graphviz

X = df.drop(['y', 'Num_of_Minimal_Injuries', 'Num_of_Major_Injuries', 'Num_of_Fatal_Injuries', 'Max_Injury'], axis=1)
y = df[['y', 'Num_of_Minimal_Injuries', 'Num_of_Major_Injuries', 'Num_of_Fatal_Injuries', 'Max_Injury']]

for col in y.columns:
    missing_count = y[col].isna().sum()
    # check if column dtype is object or string
    if y[col].dtype == 'object':
        print(f"ðŸ” Column '{col}' contains strings. Sample values:")
        print(y[col].unique()[:5])
    elif missing_count > 0:
        print(f"âš ï¸ Column '{col}' has {missing_count} missing values.")
        print(f"   Dtype: {y[col].dtype}")
        print("-" * 60)

comb_counts = y.value_counts()
valid_combinations = comb_counts[comb_counts > 1].index

mask = y.apply(tuple, axis = 1 ).isin(valid_combinations)
X = X[mask]
y = [mask]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42, stratify = y)

rf = RandomForestClassifier()
rf.fit(X_train, y_train)
y_pred = rf.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)



